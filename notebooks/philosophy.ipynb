{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "feaedff8",
      "metadata": {
        "id": "feaedff8"
      },
      "source": [
        "# Getting to Philosophy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b883d41",
      "metadata": {
        "id": "0b883d41"
      },
      "source": [
        "[Click here to run this chapter on Colab](https://colab.research.google.com/github/AllenDowney/DSIRP/blob/main/notebooks/philosophy.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a4a79b",
      "metadata": {
        "id": "f6a4a79b"
      },
      "source": [
        "# Getting to Philosophy\n",
        "\n",
        "The goal of this notebook is to develop a Web crawler that tests the\n",
        "\"Getting to Philosophy\" conjecture. As explained on [this Wikipedia page](https://en.wikipedia.org/wiki/Wikipedia:Getting_to_Philosophy):\n",
        "\n",
        "> Clicking on the first link in the main text of an English Wikipedia article, and then repeating the process for subsequent articles, usually leads to the Philosophy article. In February 2016, this was true for 97% of all articles in Wikipedia...\n",
        "\n",
        "More specifically, the link can't be in parentheses or italics, and it can't be an external link, a link to the current page, or a link to a non-existent page.\n",
        "\n",
        "We'll use the `urllib` library to download Wikipedia pages and BeautifulSoup to parse HTML text and navigate the Document Object Model (DOM)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e075e092",
      "metadata": {
        "id": "e075e092"
      },
      "source": [
        "Before we start working with Wikipedia pages, let's warm up with a minimal HTML document, which I've adapted from the BeautifulSoup documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d55b02f9",
      "metadata": {
        "id": "d55b02f9"
      },
      "outputs": [],
      "source": [
        "html_doc = \"\"\"\n",
        "<html><head><title>The Dormouse's story</title></head>\n",
        "<body>\n",
        "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
        "\n",
        "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
        "(<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>),\n",
        "<i><a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and</i>\n",
        "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
        "and they lived at the bottom of a well.</p>\n",
        "\n",
        "<p class=\"story\">...</p>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edf78b69",
      "metadata": {
        "id": "edf78b69"
      },
      "source": [
        "This document contains three links, but the first one is in parentheses and the second is in italics, so the third is the link we would follow to get to philosophy.\n",
        "\n",
        "Here's how we parse this document and make a `BeautifulSoup` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "18daf934",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "18daf934",
        "outputId": "77aad215-c410-4279-dd52-9d2abe4d77e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bs4.BeautifulSoup"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>bs4.BeautifulSoup</b><br/>def __call__(name: Optional[_StrainableElement]=None, attrs: _StrainableAttributes={}, recursive: bool=True, string: Optional[_StrainableString]=None, limit: Optional[int]=None, _stacklevel: int=2, **kwargs: _StrainableAttribute) -&gt; _QueryResults</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/bs4/__init__.py</a>A data structure representing a parsed HTML or XML document.\n",
              "\n",
              "Most of the methods you&#x27;ll call on a BeautifulSoup object are inherited from\n",
              "PageElement or Tag.\n",
              "\n",
              "Internally, this class defines the basic interface called by the\n",
              "tree builders when converting an HTML/XML document into a data\n",
              "structure. The interface abstracts away the differences between\n",
              "parsers. To write a new tree builder, you&#x27;ll need to understand\n",
              "these methods as a whole.\n",
              "\n",
              "These methods will be called by the BeautifulSoup constructor:\n",
              "  * reset()\n",
              "  * feed(markup)\n",
              "\n",
              "The tree builder may call these methods from its feed() implementation:\n",
              "  * handle_starttag(name, attrs) # See note about return value\n",
              "  * handle_endtag(name)\n",
              "  * handle_data(data) # Appends to the current data node\n",
              "  * endData(containerClass) # Ends the current data node\n",
              "\n",
              "No matter how complicated the underlying parser is, you should be\n",
              "able to build a tree using &#x27;start tag&#x27; events, &#x27;end tag&#x27; events,\n",
              "&#x27;data&#x27; events, and &quot;done with data&quot; events.\n",
              "\n",
              "If you encounter an empty-element tag (aka a self-closing tag,\n",
              "like HTML&#x27;s &lt;br&gt; tag), call handle_starttag and then\n",
              "handle_endtag.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 135);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(html_doc)\n",
        "type(soup)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c74c8fa",
      "metadata": {
        "id": "1c74c8fa"
      },
      "source": [
        "To iterate through the elements in the DOM, we can write our own implementation of depth first search, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "65f13165",
      "metadata": {
        "id": "65f13165"
      },
      "outputs": [],
      "source": [
        "def iterative_DFS(root):\n",
        "    stack = [root]\n",
        "\n",
        "    while(stack):\n",
        "        element = stack.pop()\n",
        "        yield element\n",
        "\n",
        "        children = getattr(element, \"contents\", [])\n",
        "        stack.extend(reversed(children))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48850017",
      "metadata": {
        "id": "48850017"
      },
      "source": [
        "For example, we can iterate through the elements and print all `NavigableString` elements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "53eafee6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53eafee6",
        "outputId": "7254b480-b614-4886-d370-79506e3f244b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Dormouse's story\n",
            "\n",
            "The Dormouse's story\n",
            "Once upon a time there were three little sisters; and their names were\n",
            "(Elsie),\n",
            "Lacie and\n",
            "Tillie;\n",
            "and they lived at the bottom of a well.\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "from bs4 import NavigableString\n",
        "\n",
        "for element in iterative_DFS(soup):\n",
        "    if isinstance(element, NavigableString):\n",
        "        print(element.string, end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20b7800a",
      "metadata": {
        "id": "20b7800a"
      },
      "source": [
        "But we can also use `descendants`, which does the same thing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "625f449d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "625f449d",
        "outputId": "7003f575-67ce-4fef-a869-b48b81d395d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Dormouse's story\n",
            "\n",
            "The Dormouse's story\n",
            "Once upon a time there were three little sisters; and their names were\n",
            "(Elsie),\n",
            "Lacie and\n",
            "Tillie;\n",
            "and they lived at the bottom of a well.\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "for element in soup.descendants:\n",
        "    if isinstance(element, NavigableString):\n",
        "        print(element.string, end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24608925",
      "metadata": {
        "id": "24608925"
      },
      "source": [
        "## Checking for Parentheses\n",
        "\n",
        "One theory of software development suggests you should tackle the hardest problem first, because it will drive the design. Then you can figure out how to handle the easier problems.\n",
        "\n",
        "For \"Getting to Philosophy\", one of the harder problems is to figure out whether a link is in parentheses.\n",
        "If you have a link, you could work your way outward looking for enclosing parentheses, but in a tree, that could get complicated.\n",
        "\n",
        "The alternative I chose is to iterate through the text in order, counting open and close parentheses, and yield links only if they are not enclosed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "aa828190",
      "metadata": {
        "tags": [],
        "id": "aa828190"
      },
      "outputs": [],
      "source": [
        "from bs4 import Tag\n",
        "\n",
        "def link_generator(root):\n",
        "    paren_stack = []\n",
        "\n",
        "    for element in root.descendants:\n",
        "        if isinstance(element, NavigableString):\n",
        "            for char in element.string:\n",
        "                if char == '(':\n",
        "                    paren_stack.append(char)\n",
        "                if char == ')':\n",
        "                    paren_stack.pop()\n",
        "\n",
        "        if isinstance(element, Tag) and element.name == \"a\":\n",
        "            if len(paren_stack) == 0:\n",
        "                yield element"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52b32aff",
      "metadata": {
        "id": "52b32aff"
      },
      "source": [
        "Now we can iterate through the links that are not in parentheses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d78b1c21",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d78b1c21",
        "outputId": "b3946c77-9cfc-4246-a644-b5f87d719cd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
            "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n"
          ]
        }
      ],
      "source": [
        "for link in link_generator(soup):\n",
        "    print(link)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1054af68",
      "metadata": {
        "id": "1054af68"
      },
      "source": [
        "## Checking for Italics\n",
        "\n",
        "To see whether a link is in italics, we can:\n",
        "\n",
        "1) If its parent is a `Tag` with name `a`, it's in italics.\n",
        "\n",
        "2) Otherwise we have to check the parent of the parent, and so on.\n",
        "\n",
        "3) If we get to the root without finding an italics tag, it's not in italics."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4db33e84",
      "metadata": {
        "id": "4db33e84"
      },
      "source": [
        "For example, here's the first link from `link_generator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d35a16e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d35a16e5",
        "outputId": "a892cbb1-2c04-4534-efb6-6dd1f60a1bcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "link = next(link_generator(soup))\n",
        "link"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bb6ee09",
      "metadata": {
        "id": "6bb6ee09"
      },
      "source": [
        "Its parent is an italics tag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "600997fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "600997fb",
        "outputId": "1101f2b4-4ebb-48bc-aa28-c43db97d1369"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "parent = link.parent\n",
        "isinstance(parent, Tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f6875673",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "f6875673",
        "outputId": "a3443764-ca2d-4a17-9e84-4a3c9f883c9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "parent.name"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd523372",
      "metadata": {
        "id": "fd523372"
      },
      "source": [
        "**Exercise:** Write a function called `in_italics` that takes an element and returns `True` if it is in italics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "af48fbbe",
      "metadata": {
        "id": "af48fbbe"
      },
      "outputs": [],
      "source": [
        "def in_italics(element) -> bool:\n",
        "  return link.parent.name == 'i'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93f8f3c5",
      "metadata": {
        "id": "93f8f3c5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "212f4c4c",
      "metadata": {
        "id": "212f4c4c"
      },
      "source": [
        "Then write a more general function called `in_bad_element` that takes an element and returns `True` if:\n",
        "\n",
        "* The element or one of its ancestors has a \"bad\" tag name, like `i`, or\n",
        "\n",
        "* The element or one of its ancestors is a `div` whose `class` attribute contains a \"bad\" class name.\n",
        "\n",
        "We will need the general version of this function to exclude invalid links on Wikipedia pages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "19c4e346",
      "metadata": {
        "id": "19c4e346"
      },
      "outputs": [],
      "source": [
        "def in_bad_element(element, bad_classes) -> bool:\n",
        "  while element.parent:\n",
        "    if element.name in {'i','img', 'figcaption'}:\n",
        "      return True\n",
        "    if ('class' in element.attrs):\n",
        "          for bad_class in bad_classes:\n",
        "            if bad_class in element.attrs['class']:\n",
        "              return True\n",
        "    element = element.parent\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a049eea0",
      "metadata": {
        "id": "a049eea0"
      },
      "source": [
        "## Working with Wikipedia Pages\n",
        "\n",
        "Actual Wikipedia pages are more complicated that the simple example, so it will take some effort to understand their structure and make sure we select the right \"first link\".\n",
        "\n",
        "The following cell downloads the Wikipedia page on Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "fdb4f5e6",
      "metadata": {
        "id": "fdb4f5e6"
      },
      "outputs": [],
      "source": [
        "from os.path import basename, exists\n",
        "\n",
        "def download(url):\n",
        "    filename = basename(url)\n",
        "    if not exists(filename):\n",
        "        from urllib3 import request\n",
        "        resp = request(\"GET\", url)\n",
        "        local = open(filename, 'wb')\n",
        "        local.write(resp.data)\n",
        "        local.close()\n",
        "        print('Downloaded ' + filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "95309299",
      "metadata": {
        "id": "95309299"
      },
      "outputs": [],
      "source": [
        "url = \"https://en.wikipedia.org/wiki/Python_(programming_language)\"\n",
        "download(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "330f5df2",
      "metadata": {
        "id": "330f5df2"
      },
      "source": [
        "Now we can parse it and make `soup`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "10bb4b22",
      "metadata": {
        "id": "10bb4b22"
      },
      "outputs": [],
      "source": [
        "filename = basename(url)\n",
        "fp = open(filename)\n",
        "soup2 = BeautifulSoup(fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ec384e4",
      "metadata": {
        "id": "3ec384e4"
      },
      "source": [
        "If you use a web browser to view this page, and use the Inspect Element tool to explore the structure, you'll see that the body of the article is in a `div` element with the class name `mw-body-content`.\n",
        "\n",
        "We can use `find` to get this element, and we'll use it as the root for our searches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "31215d3b",
      "metadata": {
        "tags": [],
        "id": "31215d3b"
      },
      "outputs": [],
      "source": [
        "root = soup2.find(class_='mw-body-content')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3227b5a6",
      "metadata": {
        "id": "3227b5a6"
      },
      "source": [
        "**Exercise:** Write a generator function called `valid_link_generator` that uses `link_generator` to find links that are not in parentheses; then it should filter out links that are not valid, including links that are in italics, links to external pages, etc.\n",
        "\n",
        "Test your function with a few different pages until it reliably finds the \"first link\" that seems most consistent with the spirit of the rules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "2c2e4729",
      "metadata": {
        "id": "2c2e4729"
      },
      "outputs": [],
      "source": [
        "def valid_link_generator(root):\n",
        "    paren_stack = []\n",
        "    for element in root.descendants:\n",
        "        if isinstance(element, NavigableString):\n",
        "            for char in element.string:\n",
        "                if char == '(':\n",
        "                    paren_stack.append(char)\n",
        "                if char == ')':\n",
        "                    try:\n",
        "                      paren_stack.pop()\n",
        "                    except:\n",
        "                      print(\"Pop from empty list at \", element.string)\n",
        "\n",
        "        if isinstance(element, Tag) and element.name == \"a\":\n",
        "            if (len(paren_stack) == 0\n",
        "                and not in_bad_element(element, [\"ambox\", \"mw-file-description\", \"hatnote\"])\n",
        "                ):\n",
        "                yield element"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "f9fd3f47",
      "metadata": {
        "id": "f9fd3f47"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b14f73b3",
      "metadata": {
        "id": "b14f73b3"
      },
      "source": [
        "## `WikiFetcher`\n",
        "\n",
        "When you write a Web crawler, it is easy to download too many pages too\n",
        "fast, which might violate the terms of service for the server you are\n",
        "downloading from. To avoid that, we'll use an object called\n",
        "`WikiFetcher` that does two things:\n",
        "\n",
        "1.  It encapsulates the code for downloading and parsing web pages.\n",
        "\n",
        "2.  It measures the time between requests and, if we don't leave enough\n",
        "    time between requests, it sleeps until a reasonable interval has\n",
        "    elapsed. By default, the interval is one second.\n",
        "\n",
        "Here's the definition of `WikiFetcher`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "1e6c5654",
      "metadata": {
        "id": "1e6c5654"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "import urllib3\n",
        "from bs4 import BeautifulSoup\n",
        "from time import time, sleep\n",
        "\n",
        "class WikiFetcher:\n",
        "    next_request_time = None\n",
        "    min_interval = 1  # second\n",
        "    http = urllib3.PoolManager()\n",
        "\n",
        "    def fetch_wikipedia(self, url):\n",
        "        self.sleep_if_needed()\n",
        "        fp = self.http.request('GET', url, headers={\"User-Agent\": \"DSIR\"})\n",
        "        soup = BeautifulSoup(fp.data, 'html.parser')\n",
        "        return soup\n",
        "\n",
        "    def sleep_if_needed(self):\n",
        "        if self.next_request_time:\n",
        "            sleep_time = self.next_request_time - time()\n",
        "            if sleep_time > 0:\n",
        "                sleep(sleep_time)\n",
        "\n",
        "        self.next_request_time = time() + self.min_interval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252b6528",
      "metadata": {
        "id": "252b6528"
      },
      "source": [
        "`fetch_wikipedia` takes a URL as a\n",
        "`String` and returns a BeautifulSoup object that represents the contents of the page.\n",
        "\n",
        "`sleep_if_needed` checks the time since the last\n",
        "request and sleeps if the elapsed time is less than `min_interval`.\n",
        "\n",
        "Here's an example that demonstrates how it's used:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "f97c92ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f97c92ea",
        "outputId": "b6bca527-af07-4866-dc0c-94fb9064ded5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "1765337790.048612\n",
            "1765337791.0428593\n",
            "1765337792.0428362\n"
          ]
        }
      ],
      "source": [
        "wf = WikiFetcher()\n",
        "url = \"https://en.wikipedia.org/wiki/Python_(programming_language)\"\n",
        "print(time())\n",
        "wf.fetch_wikipedia(url)\n",
        "print(time())\n",
        "wf.fetch_wikipedia(url)\n",
        "print(time())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5335b9a6",
      "metadata": {
        "id": "5335b9a6"
      },
      "source": [
        "If things have gone according to plan, the three timestamps should be no less than 1 second apart, which is consistent with the terms in Wikipedia's [robots.txt](https://en.wikipedia.org/robots.txt):\n",
        "\n",
        "> Friendly, low-speed bots are welcome viewing article pages, but not\n",
        "dynamically-generated pages please."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66332ab6",
      "metadata": {
        "id": "66332ab6"
      },
      "source": [
        "**Exercise:** Now let's pull it all together. Write a function called `get_to_philosophy` that takes as a parameter the URL of a Wikipedia page. It should:\n",
        "\n",
        "1.  Use the `WikiFetcher` object we just created to download and parse the page.\n",
        "\n",
        "2.  Traverse the resulting `BeautifulSoup` object to find the first valid link according to the spirit of the rules.\n",
        "\n",
        "3.  If the page has no links, or if the first link is a page we have already seen, the program should indicate failure and exit.\n",
        "\n",
        "4.  If the link matches the URL of the Wikipedia page on philosophy, the program should indicate success and exit.\n",
        "\n",
        "5.  Otherwise it should go back to Step 1 (although you might want to put a limit on the number of hops).\n",
        "\n",
        "The program should build a list of the URLs it visits and display the\n",
        "results at the end (whether it succeeds or fails).\n",
        "\n",
        "Since the links you find are relative, you might find the `urljoin` function helpful:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ab913376",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ab913376",
        "outputId": "b42bbfd7-9300-45fc-be96-dec9512552f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://en.wikipedia.org/wiki/Interpreted_language'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from urllib.parse import urljoin\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/Python_(programming_language)\"\n",
        "relative_path = \"/wiki/Interpreted_language\"\n",
        "\n",
        "urljoin(url, relative_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "39848591",
      "metadata": {
        "id": "39848591"
      },
      "outputs": [],
      "source": [
        "def get_to_philosophy(url):\n",
        "    wf = WikiFetcher()\n",
        "    visited = set()\n",
        "    base_url = 'https://en.wikipedia.org/'\n",
        "    while True:\n",
        "      print(\"Visiting: \" + url)\n",
        "      soup = wf.fetch_wikipedia(url)\n",
        "      root = soup.find(class_=\"mw-body-content\")\n",
        "      visited.add(url)\n",
        "      try:\n",
        "        first_link = next(valid_link_generator(root)).attrs[\"href\"]\n",
        "      except StopIteration:\n",
        "        print(\"Failure no link\")\n",
        "        return\n",
        "      if first_link == \"/wiki/Philosophy\":\n",
        "          print(\"Success\")\n",
        "          return\n",
        "      if first_link in visited:\n",
        "          print(\"Failure cycle\" + first_link)\n",
        "          return\n",
        "      visited.add(first_link)\n",
        "      new_url = urljoin(base_url, first_link)\n",
        "      url = new_url"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vh1VaOhDdOLx"
      },
      "id": "vh1VaOhDdOLx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "147b670c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "147b670c",
        "outputId": "51b06c75-f6ad-4efd-838a-5117565c9eb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visiting: https://en.wikipedia.org/wiki/Python_(programming_language)\n",
            "Visiting: https://en.wikipedia.org/wiki/Metaclass\n",
            "Visiting: https://en.wikipedia.org/wiki/Object-oriented_programming\n",
            "Visiting: https://en.wikipedia.org/wiki/Programming_paradigm\n",
            "Visiting: https://en.wikipedia.org/wiki/Computer_program\n",
            "Pop from empty list at  2) A creature billows fire if one of its parents billows fire:\n",
            "\n",
            "Pop from empty list at  3) A thing X is a parent of a thing Y if X is the mother of Y or X is the father of Y:\n",
            "\n",
            "Pop from empty list at  4) A thing is a creature if the thing is a dragon:\n",
            "\n",
            "Pop from empty list at  5) Norberta is a dragon, and Puff is a creature. Norberta is the mother of Puff.\n",
            "\n",
            "Visiting: https://en.wikipedia.org/wiki/Recursion_(computer_science)\n",
            "Visiting: https://en.wikipedia.org/wiki/Computer_science\n",
            "Visiting: https://en.wikipedia.org/wiki/Programming_language_theory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1601292495.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_to_philosophy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3641148760.py\u001b[0m in \u001b[0;36mget_to_philosophy\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mfirst_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_link_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"href\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mfirst_link\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m           \u001b[0mfirst_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_link_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"href\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failure no link\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3720473793.py\u001b[0m in \u001b[0;36mvalid_link_generator\u001b[0;34m(root)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             if (len(paren_stack) == 0 \n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_bad_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"ambox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mw-file-description\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hatnote\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 ):\n\u001b[1;32m     18\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "get_to_philosophy(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8a3d580",
      "metadata": {
        "tags": [],
        "id": "d8a3d580"
      },
      "source": [
        "*Data Structures and Information Retrieval in Python*\n",
        "\n",
        "Copyright 2021 Allen Downey\n",
        "\n",
        "License: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}